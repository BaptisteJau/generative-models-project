import streamlit as st
import os
import sys
import torch
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
import glob
from datetime import datetime
import io

# Ajouter le r√©pertoire parent au path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# Importer les classes des mod√®les (suppression du mod√®le de diffusion)
from src.models.transformer.transformer_model import TransformerModel, clean_repetitions
from src.models.cnn.deep_cnn import DeepCNN
from src.creative.latent_exploration import LatentExplorer

# Configuration de la page
st.set_page_config(
    page_title="Mod√®les G√©n√©ratifs - Visualisation",
    page_icon="üß†",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Styles CSS personnalis√©s
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        margin-bottom: 1rem;
    }
    .model-header {
        font-size: 1.8rem;
        font-weight: bold;
        margin-top: 2rem;
        padding-top: 1rem;
        border-top: 1px solid #ccc;
    }
    .section-header {
        font-size: 1.3rem;
        font-weight: bold;
        margin-top: 1rem;
    }
    .output-box {
        background-color: #f0f2f6;
        padding: 1.5rem;
        border-radius: 0.5rem;
        margin: 1rem 0;
    }
    .hint-text {
        font-size: 0.9rem;
        color: #666;
        font-style: italic;
    }
</style>
""", unsafe_allow_html=True)

# Variables globales pour stocker les mod√®les charg√©s
@st.cache_resource
def load_transformer_model(model_path):
    """Charge le mod√®le Transformer avec mise en cache"""
    try:
        model = TransformerModel(
            vocab_size=50257,
            d_model=128,
            nhead=2,
            num_encoder_layers=2,
            num_decoder_layers=2,
            dim_feedforward=512,
            dropout=0.1
        )
        model.load_state_dict(torch.load(model_path, map_location='cpu', weights_only=True))
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        model.to(device)
        model.eval()
        return model, True
    except Exception as e:
        st.error(f"Erreur lors du chargement du mod√®le Transformer: {e}")
        return None, False

@st.cache_resource
def load_cnn_model(model_path):
    """Charge le mod√®le CNN/GAN avec mise en cache"""
    try:
        model = DeepCNN(input_shape=(64, 64, 3), latent_dim=100)
        model.load_model(model_path)
        return model, True
    except Exception as e:
        st.error(f"Erreur lors du chargement du mod√®le GAN: {e}")
        return None, False

def find_latest_model(model_type):
    """Trouve le chemin du dernier mod√®le entra√Æn√© d'un type sp√©cifique"""
    if model_type == "transformer":
        pattern = "results/transformer_*/models/transformer_final.pt"
    elif model_type == "cnn":
        pattern = "checkpoints/*/gan_checkpoint_*_generator.h5"
    else:
        return None
    
    paths = glob.glob(pattern)
    if not paths:
        return None
    
    return max(paths, key=os.path.getctime)

def create_sidebar():
    """Cr√©e la barre lat√©rale avec les options de chargement des mod√®les"""
    st.sidebar.markdown("## Configuration des Mod√®les")
    
    # Transformer
    st.sidebar.markdown("### Transformer (Texte)")
    transformer_use_latest = st.sidebar.checkbox("Utiliser le dernier mod√®le Transformer", value=True)
    transformer_path = find_latest_model("transformer")
    
    if transformer_use_latest:
        st.sidebar.text(f"Mod√®le: {transformer_path}")
    else:
        transformer_path = st.sidebar.text_input("Chemin du mod√®le Transformer", value=transformer_path or "")
    
    # CNN/GAN
    st.sidebar.markdown("### GAN (Images)")
    cnn_use_latest = st.sidebar.checkbox("Utiliser le dernier mod√®le GAN", value=True)
    cnn_path = find_latest_model("cnn")
    
    if cnn_use_latest:
        st.sidebar.text(f"Mod√®le: {cnn_path}")
    else:
        cnn_path = st.sidebar.text_input("Chemin du mod√®le GAN", value=cnn_path or "")
    
    return transformer_path, cnn_path

def transformer_ui(model_path):
    """Interface utilisateur pour le mod√®le Transformer"""
    st.markdown('<div class="model-header">Transformer - G√©n√©ration de Texte</div>', unsafe_allow_html=True)
    
    if not model_path:
        st.warning("Aucun mod√®le Transformer trouv√©. Veuillez sp√©cifier un chemin dans la barre lat√©rale.")
        return
    
    # Charger le mod√®le si n√©cessaire
    model, success = load_transformer_model(model_path)
    if not success:
        return
    
    # Interface utilisateur
    prompt = st.text_input("Prompt de d√©part:", value="Once upon a time")
    
    col1, col2, col3 = st.columns(3)
    with col1:
        temperature = st.slider("Temp√©rature:", min_value=0.1, max_value=2.0, value=0.7, step=0.1, 
                              help="Contr√¥le la cr√©ativit√© (plus √©lev√© = plus cr√©atif)")
    with col2:
        top_k = st.slider("Top-K:", min_value=1, max_value=100, value=50, 
                        help="Limite le choix aux K tokens les plus probables")
    with col3:
        top_p = st.slider("Top-P:", min_value=0.1, max_value=1.0, value=0.95, step=0.05, 
                        help="Limite aux tokens couvrant P% de la probabilit√© cumulative")
    
    col1, col2 = st.columns(2)
    with col1:
        repetition_penalty = st.slider("P√©nalit√© de r√©p√©tition:", min_value=1.0, max_value=3.0, value=2.0, step=0.1,
                                    help="P√©nalise les tokens r√©p√©t√©s (plus √©lev√© = moins de r√©p√©titions)")
    with col2:
        max_length = st.slider("Longueur maximale:", min_value=50, max_value=500, value=200, step=10)
    
    # G√©n√©ration de texte
    if st.button("G√©n√©rer du texte"):
        with st.spinner("G√©n√©ration en cours..."):
            generated_text = model.generate(
                prompt,
                max_length=max_length,
                temperature=temperature,
                top_k=top_k,
                top_p=top_p,
                repetition_penalty=repetition_penalty
            )
            
            # Post-traitement pour am√©liorer la qualit√©
            cleaned_text = clean_repetitions(generated_text)
            
            # Afficher le r√©sultat
            st.markdown('<div class="section-header">Texte g√©n√©r√©:</div>', unsafe_allow_html=True)
            st.markdown(f'<div class="output-box">{cleaned_text}</div>', unsafe_allow_html=True)
            
            # Boutons pour sauvegarder et partager
            col1, col2 = st.columns(2)
            with col1:
                if st.button("Sauvegarder comme .txt"):
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    filename = f"transformer_generation_{timestamp}.txt"
                    with open(os.path.join("results", filename), "w", encoding="utf-8") as f:
                        f.write(cleaned_text)
                    st.success(f"Sauvegard√© dans results/{filename}")

def gan_ui(model_path):
    """Interface utilisateur am√©lior√©e pour le mod√®le GAN"""
    st.markdown('<div class="model-header">GAN - G√©n√©ration d\'Images</div>', unsafe_allow_html=True)
    
    if not model_path:
        st.warning("Aucun mod√®le GAN trouv√©. Veuillez sp√©cifier un chemin dans la barre lat√©rale.")
        return
    
    # Charger le mod√®le si n√©cessaire
    model, success = load_cnn_model(model_path)
    if not success:
        return
    
    # Interface am√©lior√©e avec tabs
    tabs = st.tabs(["G√©n√©ration basique", "Param√®tres avanc√©s", "Exploration latente"])
    
    with tabs[0]:
        st.markdown('<div class="section-header">G√©n√©ration d\'images</div>', unsafe_allow_html=True)
        
        col1, col2 = st.columns(2)
        with col1:
            num_images = st.slider("Nombre d'images:", min_value=1, max_value=16, value=4)
        with col2:
            image_size = st.selectbox("Taille des images:", options=["64x64", "128x128"], index=0)
        
        # G√©n√©ration d'images
        if st.button("G√©n√©rer des images"):
            with st.spinner("G√©n√©ration en cours..."):
                try:
                    generated_images = model.generate_images(num_images=num_images)
                    
                    # Afficher les images g√©n√©r√©es
                    st.markdown('<div class="section-header">Images g√©n√©r√©es:</div>', unsafe_allow_html=True)
                    
                    # Organiser en grille
                    cols = min(4, num_images)
                    rows = (num_images + cols - 1) // cols
                    
                    for i in range(rows):
                        row_cols = st.columns(cols)
                        for j in range(cols):
                            idx = i * cols + j
                            if idx < num_images:
                                img = generated_images[idx]
                                # Normaliser si n√©cessaire
                                if img.min() < 0:
                                    img = (img + 1) / 2
                                if isinstance(img, torch.Tensor):
                                    img = img.detach().cpu().numpy().transpose(1, 2, 0)
                                elif isinstance(img, np.ndarray) and img.shape[0] == 3:
                                    img = img.transpose(1, 2, 0)
                                row_cols[j].image(img, caption=f"Image {idx+1}", use_column_width=True)
                    
                except Exception as e:
                    st.error(f"Erreur lors de la g√©n√©ration d'images: {e}")
    
    with tabs[1]:
        st.markdown('<div class="section-header">Param√®tres avanc√©s de g√©n√©ration</div>', unsafe_allow_html=True)
        
        truncation = st.slider("Troncature:", min_value=0.1, max_value=1.5, value=0.8, step=0.1,
                             help="Valeurs plus basses donnent des images plus 'moyennes', plus √©lev√©es plus diversifi√©es")
        
        # Seed for reproducibility
        use_seed = st.checkbox("Utiliser un seed (reproductibilit√©)", value=False)
        seed = st.number_input("Seed:", value=42, disabled=not use_seed)
        
        if st.button("G√©n√©rer avec param√®tres avanc√©s"):
            with st.spinner("G√©n√©ration en cours..."):
                try:
                    # Set seed if needed
                    if use_seed:
                        np.random.seed(int(seed))
                    
                    # Generate images with truncation
                    generated_images = model.generate_images(num_images=4, truncation=truncation)
                    
                    # Display images in 2x2 grid
                    st.markdown('<div class="section-header">Images g√©n√©r√©es avec param√®tres avanc√©s:</div>', unsafe_allow_html=True)
                    col1, col2 = st.columns(2)
                    col3, col4 = st.columns(2)
                    
                    cols = [col1, col2, col3, col4]
                    for i, img in enumerate(generated_images[:4]):
                        if img.min() < 0:
                            img = (img + 1) / 2
                        cols[i].image(img, caption=f"Image {i+1} (truncation={truncation})", use_column_width=True)
                    
                except Exception as e:
                    st.error(f"Erreur lors de la g√©n√©ration d'images: {e}")
    
    with tabs[2]:
        st.markdown('<div class="section-header">Exploration latente avanc√©e</div>', unsafe_allow_html=True)
        
        exploration_type = st.selectbox(
            "Type d'exploration:",
            options=["Interpolation lin√©aire", "M√©lange de styles", "Marche al√©atoire"],
            index=0
        )
        
        if exploration_type == "Interpolation lin√©aire":
            steps = st.slider("Nombre d'√©tapes d'interpolation:", min_value=5, max_value=30, value=10)
            
            if st.button("G√©n√©rer l'interpolation"):
                with st.spinner("Cr√©ation de l'interpolation..."):
                    try:
                        explorer = LatentExplorer(model)
                        
                        # G√©n√©rer les images interpol√©es
                        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                        output_path = os.path.join("results", f"latent_interpolation_{timestamp}.gif")
                        explorer.latent_space_interpolation(n_steps=steps, animate=True, save_path=output_path)
                        
                        # Afficher le GIF
                        with open(output_path, 'rb') as f:
                            gif_data = f.read()
                            st.image(gif_data, caption="Interpolation dans l'espace latent")
                        
                    except Exception as e:
                        st.error(f"Erreur lors de l'exploration latente: {e}")
                        
        elif exploration_type == "M√©lange de styles":
            num_sources = st.slider("Nombre d'images sources:", min_value=2, max_value=5, value=3)
            
            if st.button("G√©n√©rer le m√©lange de styles"):
                with st.spinner("Cr√©ation du m√©lange de styles..."):
                    try:
                        explorer = LatentExplorer(model)
                        
                        # G√©n√©rer la grille de m√©langes de style
                        style_grid = explorer.style_mixing(num_samples=num_sources)
                        
                        # Afficher la grille
                        st.image(style_grid, caption="M√©lange de styles (lignes/colonnes = images sources)", use_column_width=True)
                        
                    except Exception as e:
                        st.error(f"Erreur lors du m√©lange de styles: {e}")

def main():
    st.markdown('<div class="main-header">Visualisation des Mod√®les G√©n√©ratifs</div>', unsafe_allow_html=True)
    
    st.write("""
    Cette application permet de visualiser et d'interagir avec deux types de mod√®les g√©n√©ratifs d√©velopp√©s dans ce projet:
    - **Transformer**: G√©n√©ration de texte avec contr√¥le de divers param√®tres
    - **GAN (CNN)**: G√©n√©ration d'images et exploration de l'espace latent
    
    Utilisez les contr√¥les dans la barre lat√©rale pour configurer les mod√®les, puis interagissez avec chaque section ci-dessous.
    """)
    
    # Configuration des mod√®les via la barre lat√©rale (suppression du mod√®le de diffusion)
    transformer_path, cnn_path = create_sidebar()
    
    # Interface pour chaque mod√®le (suppression du mod√®le de diffusion)
    transformer_ui(transformer_path)
    gan_ui(cnn_path)
    
    # Footer
    st.markdown("---")
    st.markdown('<div class="hint-text">Projet de mod√®les g√©n√©ratifs - Technologies utilis√©es: PyTorch, TensorFlow, Streamlit</div>', unsafe_allow_html=True)

if __name__ == "__main__":
    main()